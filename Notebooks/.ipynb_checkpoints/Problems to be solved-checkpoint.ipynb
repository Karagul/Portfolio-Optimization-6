{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems and Comments \n",
    "---\n",
    "\n",
    "### There are a few problems with this program and with the model itself (that can be solved): \n",
    "\n",
    "1. Estimation of Covariance matrix is very messy, .cov() is a rather inaccurate estimation of the covariance matrix \n",
    "\n",
    "2. Exp. Returns (Mean Returns) is a quite bad criterion for futurue returns, Markowitz himself said that\n",
    "\n",
    "3. Mus vector (exponentially distributed), is rather inaccurate at finding the 'true' convex region. The mus vector might be a tricky thing to solve; it is the parameter that the model solves for a given variance - so as of now this is a exponentially distributed scale, which is later multiplied by the covariance matrix in the optimization (see: https://cvxopt.org/examples/book/portfolio.html). More intuitively (and closer to the actual model), mus should be distributed between the minimum return (either simply 0, or the return of the minimum-return asset) and the maximum return asset. The problem is, that the constraint matrices will have to be modified accordingly (instead of multiplying mu by covariance)\n",
    "\n",
    "4. This is *the* foundational model in portfolio optimization, better and more robust models have been suggested\n",
    "\n",
    "5. Vizualisation of the portfolio of the results is not great as of now, there are many cool things that can be done (@Ash), simply way would be to plot the efficient frontier (like in the picture below), play with visualization of portfolios (aka pie charts, doughnut charts, stacked bar chart (to show distriubtion with different risk) or tree maps)\n",
    "\n",
    "![Tangent Portfolio](https://github.com/kgeoffrey/Mean-Variance-Model/blob/master/Notebooks/tangentportfolio.gif?raw=true)\n",
    "\n",
    "---\n",
    "\n",
    "### Some solutions I thought of \n",
    "\n",
    "1. The math here can get *hard*, luckily there are some libraries that can help with estimating a robust covariance matrix (http://scikit-learn.org/stable/modules/covariance.html)\n",
    "\n",
    "2. This can be done by simply setting all returns to 1 or using log returns instead! (there is a pitfall though: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1549328) \n",
    "\n",
    "3. Tricky and probabaly the most work, a quantopian user managed to do this (https://www.quantopian.com/posts/the-efficient-frontier-markowitz-portfolio-optimization-in-python-using-cvxopt). The program as of now can allow for short selling and put restrictions on invidual assets weights,by modifying h and G matrices accordingly. I will have to figure out new ways of implementing these features after using the better formulation of the optimization probelm\n",
    "\n",
    "4. The Mean-Absolute-Deviation Model is finished and ready for upload (it is not parametrized however, it only solves for the minimum variance portfolio - also the region is not convex, a story for another time). Interesting to implement would be the Black-Litterman Model (as it allows to incorporate one's own views; aka I think security x will outperfom security y), there are other models but they are very difficult to implement (downside risk models etc.)\n",
    "\n",
    "5. probably coolest and easiest to do rn, viz of results via matplotlib and also interactive via bokeh. I do have a very cool idea for a visualization of the process of finding 'optimal portfolios', by running a montecarlo optimization (random plotting to show how the frontier emerges) and saving it as a GIF (imagine the karma :D). Here is a reddit link that explains how to do this with in python for approximating e: https://www.reddit.com/r/dataisbeautiful/comments/91rgzy/monte_carlo_simulation_of_e_oc/e3046ph/, also see below for reference of what it could look like!\n",
    "\n",
    "![Montecarlo Optimization](https://github.com/kgeoffrey/Mean-Variance-Model/blob/master/Notebooks/ezgif.com-video-to-gif.gif?raw=true)\n",
    "\n",
    "Apparently gif is too large for github, but it will display in your notebook! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put libraries to be used here\n",
    "\n",
    "# libs for solving problem\n",
    "import decimal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxopt as opt\n",
    "from cvxopt import blas, solvers\n",
    "import quandl\n",
    "# API configuration here\n",
    "quandl.ApiConfig.api_key = \"VAA5bZ67DimoDkvMStuG\"\n",
    "solvers.options['show_progress'] = False\n",
    "\n",
    "\n",
    "# libs for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_notebook, output_file, save\n",
    "from bokeh.models import ColumnDataSource, HoverTool, CheckboxGroup, Panel\n",
    "from bokeh.models.widgets import RangeSlider, Slider, Tabs\n",
    "from bokeh.palettes import Category10_5, Category20_16\n",
    "from bokeh.layouts import column, row, WidgetBox\n",
    "from bokeh.application.handlers import FunctionHandler\n",
    "from bokeh.application import Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Below I will try to figure out how to reformulate the problem as described in 3.\n",
    "\n",
    "Need to construct new h and G matrices to adjust return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the correct implementatio by the quantopian user\n",
    "\n",
    "def optimal_portfolio(returns):\n",
    "    n = len(returns)\n",
    "    returns = np.asmatrix(returns)\n",
    "    \n",
    "   \n",
    "    # Convert to cvxopt matrices\n",
    "    S = opt.matrix(np.cov(returns))\n",
    "    pbar = opt.matrix(np.mean(returns, axis=1))\n",
    "\n",
    "    # Determine trial mus based on observed returns\n",
    "    N=25\n",
    "    mus_min=max(min(pbar),0)\n",
    "    mus_max=max(pbar)\n",
    "    mus_step=(mus_max - mus_min) / (N-1)\n",
    "    mus = [mus_min + i*mus_step for i in range(N)]\n",
    "    \n",
    "    \n",
    "    # print mus\n",
    "\n",
    "    # Create constraint matrices\n",
    "    G=opt.matrix(np.concatenate((-np.transpose(pbar),-np.identity(n)),0))\n",
    "    A = opt.matrix(1.0, (1, n))\n",
    "    b = opt.matrix(1.0)\n",
    "    \n",
    "    # Calculate efficient frontier weights using quadratic programming\n",
    "    portfolios=[]\n",
    "    for r_min in mus:\n",
    "       h=opt.matrix(np.concatenate((-np.ones((1,1))*r_min,np.zeros((n,1))),0))\n",
    "       sol = solvers.qp(S, -pbar, G, h, A, b)['x']\n",
    "       \n",
    "       portfolios.append(sol)\n",
    "    \n",
    "    ## CALCULATE RISKS AND RETURNS FOR FRONTIER\n",
    "    returns = [blas.dot(pbar, x) for x in portfolios]\n",
    "    risks = [np.sqrt(blas.dot(x, S*x)) for x in portfolios]\n",
    "    ## CALCULATE THE 2ND DEGREE POLYNOMIAL OF THE FRONTIER CURVE\n",
    "    m1 = np.polyfit(returns, risks, 2)\n",
    "    x1 = np.sqrt(m1[2] / m1[0])\n",
    "    # CALCULATE THE OPTIMAL PORTFOLIO\n",
    "    h=opt.matrix(np.concatenate((-np.ones((1,1))*x1,np.zeros((n,1))),0))\n",
    "    wt = solvers.qp(S, -pbar, G, h, A, b)['x']\n",
    "    return np.asarray(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01829769]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "pbar = np.mean(returns, axis=1) \n",
    "n = len(returns)\n",
    "r_min = np.min(pbar)\n",
    "\n",
    "h=(np.concatenate((-np.ones((1,1))*r_min,np.zeros((n,1))),0))\n",
    "#G=np.concatenate((-np.transpose(pbar),-np.identity(n)),0)\n",
    "\n",
    "print(h)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.83e-02  8.30e-03 -9.56e-05 -4.08e-03  4.77e-04 -7.27e-03  1.10e-02 ... ]\n",
      "[-1.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -1.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -1.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -1.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -1.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -1.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -1.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "[-0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 -0.00e+00 ... ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = len(returns)\n",
    "returns = np.asmatrix(returns)\n",
    "pbar = opt.matrix(np.mean(returns, axis=1))\n",
    "G=opt.matrix(np.concatenate((-np.transpose(pbar),-np.identity(n)),0))\n",
    "\n",
    "print(G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualization \n",
    "\n",
    "Below we can work on 5. visulatization. I simply posted the code from the other notebook (without the pie-charts, doughnut chart or risk-return plots). Also simplified the code, so it is more readable, simply run the cell and play with the output below! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. List of stock tickers \n",
    "\n",
    "stocks1 = ['AMD', 'NVDA', 'OKE', 'CHK', 'NEM', 'AMAT', 'ALB', 'FCX', 'HPE', 'IDXX', 'WMB']\n",
    "stocks2 = ['TIVO', 'JCP', 'F']\n",
    "\n",
    "## 2. Getting Data for the stock tickers \n",
    "\n",
    "def datafunction(tickers):\n",
    "    data = quandl.get_table('WIKI/PRICES', ticker = tickers, \n",
    "                            qopts = { 'columns': ['ticker', 'date', 'adj_close'] },\n",
    "                            date = { 'gte': '2017-11-31', 'lte': '2017-12-31' }, \n",
    "                            paginate=True)\n",
    "    new = data.set_index('date')\n",
    "    # use pandas pivot function to sort adj_close by tickers\n",
    "    clean_data = new.pivot(columns='ticker')\n",
    "    return clean_data\n",
    "\n",
    "stocklist = stocks1 + stocks2\n",
    "clean_data = datafunction(stocklist)\n",
    "\n",
    "## 3. Parameters (don't change for now, you may change Scale to plot more portfolios!)\n",
    "\n",
    "Minimal_gewicht1 = -0.0\n",
    "Maximal_gewicht1 = 0.1\n",
    "Minimal_gewicht2 = 0.05\n",
    "Maximal_gewicht2 = 0.15\n",
    "Scale = 100 \n",
    "Riskaversion = 99 \n",
    "rf = 0.01 \n",
    "\n",
    "## 4. Transforming Data for optimization \n",
    "\n",
    "returnss = (clean_data.pct_change().dropna())\n",
    "number = len(stocklist)\n",
    "returns = returnss.values #as_matrix()\n",
    "\n",
    "## 5. Optimization! various outputs will explain in the cell below! \n",
    "\n",
    "def optimal_portfolio(returns):\n",
    "    \n",
    "    n = len(returns)\n",
    "    N1 = len(stocks1)\n",
    "    N2 = len(stocks2)\n",
    "    returns = np.asmatrix(returns)\n",
    "    \n",
    "    G = Scale\n",
    "    mus = [10**(5.0 * t/G - 1.0) for t in range(G)]\n",
    "\n",
    "    S = opt.matrix(np.cov(returns))\n",
    "    pbar = opt.matrix(np.mean(returns, axis=1))\n",
    "    \n",
    "    dank = -np.array(np.eye(n))\n",
    "    dabbie = np.array(np.eye(n))\n",
    "    ye = np.vstack((dank, dabbie))\n",
    "    G = opt.matrix(ye, tc='d')\n",
    "    \n",
    "    d1 = -np.ones((N1,1))*Minimal_gewicht1 \n",
    "    e1 = np.ones((N1,1))*Maximal_gewicht1\n",
    "    d2 = -np.ones((N2,1))*Minimal_gewicht2\n",
    "    e2 =  np.ones((N2,1))*Maximal_gewicht2\n",
    "    min_constraint = np.vstack((d1, d2))\n",
    "    max_constraint = np.vstack((e1, e2))\n",
    "\n",
    "    dodo = np.vstack((min_constraint, max_constraint))\n",
    "    h = opt.matrix(dodo, tc='d')\n",
    "    A = opt.matrix(1.0, (1, n))\n",
    "    b = opt.matrix(1.0)\n",
    "\n",
    "    \n",
    "    # Calculate efficient frontier weights\n",
    "    portfolios = [solvers.qp(mu*S, -pbar, G, h, A, b)['x'] for mu in mus]\n",
    "    \n",
    "    # CALCULATE RISKS AND RETURNS FOR FRONTIER  (will add back later)\n",
    "    returns = np.asarray([blas.dot(pbar, x) for x in portfolios])\n",
    "    risks = np.asarray([np.sqrt(blas.dot(x, S*x)) for x in portfolios])\n",
    "    \n",
    "    # Maximum Return Portfolio (will always return weights with 100% in asset with maximum mean return)\n",
    "    m1 = np.polyfit(returns, risks, 2)\n",
    "    x1 = np.sqrt((m1[2])/ m1[0])\n",
    "    maxr_opt = solvers.qp(opt.matrix(x1 * S), -pbar, G, h, A, b)['x']\n",
    "    \n",
    "    # approximates the position of the maximum Sharpe portfolio (also called tangent portfolio)\n",
    "    # the bigger the scale parameter the more accurate the calculation of the maximum sharpe portfolio!\n",
    "    slope = (returns-(rf/252))/risks\n",
    "    sharpe_opt = slope.argmax()\n",
    "    \n",
    "    # Minimum Variance Portfolio\n",
    "    mini_var =  np.array(mus).max()\n",
    "    minv_opt = solvers.qp(opt.matrix(mini_var * S), -pbar, G, h, A, b)['x']\n",
    "    \n",
    "    return np.asarray(maxr_opt), returns, risks, portfolios, sharpe_opt, mini_var\n",
    "\n",
    "max_return_weights, exp_returns, exp_risk, weights, max_sharpe_weights, min_var_weights = optimal_portfolio(returns.T)\n",
    "\n",
    "\n",
    "#index portfolios on the efficient frontier here\n",
    "test1=np.array(opt.matrix(weights))\n",
    "sublist=[test1[n:n+number] for n in range(0,len(test1),number)]\n",
    "real=sublist[Riskaversion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.99980916e-02]\n",
      " [9.99999882e-02]\n",
      " [2.42207863e-08]\n",
      " [1.78103949e-07]\n",
      " [9.99999859e-02]\n",
      " [9.99999986e-02]\n",
      " [9.99999894e-02]\n",
      " [9.99999931e-02]\n",
      " [1.52907400e-08]\n",
      " [9.99999909e-02]\n",
      " [1.73426657e-06]\n",
      " [1.49999994e-01]\n",
      " [5.00000202e-02]\n",
      " [1.49999996e-01]]\n"
     ]
    }
   ],
   "source": [
    "## You can play with the output here! simply run all the code above! \n",
    "\n",
    "# the variable sublist, containst a list (of 100? --> check scale variable) of portfolios on the optimal boundary\n",
    "\n",
    "#This prints the maximum sharpe portfolio for instance! \n",
    "print(sublist[max_sharpe_weights])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
